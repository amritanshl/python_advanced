{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e80b482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# end_to_end_ml.py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# 1) Create synthetic dataset (tabular)\n",
    "rng = np.random.default_rng(0)\n",
    "n = 500  # number of samples\n",
    "\n",
    "age = rng.integers(18, 80, size=n)                       # numeric\n",
    "income = rng.normal(loc=50_000, scale=20_000, size=n)    # numeric\n",
    "gender = rng.choice(['M', 'F'], size=n, p=[0.55, 0.45])  # categorical\n",
    "bp = rng.normal(loc=120, scale=15, size=n)               # numeric: blood pressure\n",
    "smoker = rng.choice(['yes', 'no'], size=n, p=[0.2, 0.8]) # categorical\n",
    "\n",
    "# construct a target with some rule + noise\n",
    "risk_score = (0.03 * (age - 40) + 0.00002 * (income - 50_000) +\n",
    "              0.02 * (bp - 120) + (gender == 'M') * 0.1 + (smoker == 'yes') * 0.3)\n",
    "prob = 1 / (1 + np.exp(-risk_score))\n",
    "y = (rng.random(size=n) < prob).astype(int)  # binary label: 1 = high risk, 0 = low risk\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'age': age,\n",
    "    'income': income,\n",
    "    'gender': gender,\n",
    "    'bp': bp,\n",
    "    'smoker': smoker,\n",
    "    'label': y\n",
    "})\n",
    "\n",
    "# 2) Introduce some missing values for demonstration\n",
    "mask = rng.random(size=n) < 0.05\n",
    "df.loc[mask, 'income'] = np.nan\n",
    "mask2 = rng.random(size=n) < 0.03\n",
    "df.loc[mask2, 'bp'] = np.nan\n",
    "\n",
    "# 3) Train/test split\n",
    "X = df.drop(columns=['label'])\n",
    "y = df['label'].to_numpy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# 4) Preprocessing pipeline\n",
    "numeric_features = ['age', 'income', 'bp']\n",
    "numeric_transformer = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),   # fill missing numeric values\n",
    "    ('scaler', StandardScaler())                     # standardize\n",
    "])\n",
    "\n",
    "categorical_features = ['gender', 'smoker']\n",
    "categorical_transformer = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')), \n",
    "    ('onehot', OneHotEncoder(drop='first', sparse=False))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', numeric_transformer, numeric_features),\n",
    "    ('cat', categorical_transformer, categorical_features)\n",
    "], remainder='drop')\n",
    "\n",
    "# 5) Define model candidates wrapped in pipelines\n",
    "models = {\n",
    "    'decision_tree': Pipeline([('pre', preprocessor),\n",
    "                               ('clf', DecisionTreeClassifier(random_state=0))]),\n",
    "    'random_forest': Pipeline([('pre', preprocessor),\n",
    "                               ('clf', RandomForestClassifier(random_state=0))]),\n",
    "    'svm': Pipeline([('pre', preprocessor),\n",
    "                     ('clf', SVC(probability=False, random_state=0))]),\n",
    "    'knn': Pipeline([('pre', preprocessor),\n",
    "                     ('clf', KNeighborsClassifier())])\n",
    "}\n",
    "\n",
    "# 6) Simple cross-validated baseline scores\n",
    "print(\"Cross-validated accuracy (3-fold) for each model:\")\n",
    "for name, pipe in models.items():\n",
    "    scores = cross_val_score(pipe, X_train, y_train, cv=3, scoring='accuracy')\n",
    "    print(f\"  {name}: mean={scores.mean():.3f} std={scores.std():.3f}\")\n",
    "\n",
    "# 7) Grid search (example) for Random Forest and SVM\n",
    "param_grid_rf = {\n",
    "    'clf__n_estimators': [50, 100],\n",
    "    'clf__max_depth': [None, 5, 10]\n",
    "}\n",
    "grid_rf = GridSearchCV(models['random_forest'], param_grid_rf, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "grid_rf.fit(X_train, y_train)\n",
    "print(\"Random Forest best params:\", grid_rf.best_params_)\n",
    "print(\"Random Forest best CV score:\", grid_rf.best_score_)\n",
    "\n",
    "param_grid_svm = {\n",
    "    'clf__C': [0.1, 1.0, 10.0],\n",
    "    'clf__kernel': ['rbf', 'linear']\n",
    "}\n",
    "grid_svm = GridSearchCV(models['svm'], param_grid_svm, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "grid_svm.fit(X_train, y_train)\n",
    "print(\"SVM best params:\", grid_svm.best_params_)\n",
    "print(\"SVM best CV score:\", grid_svm.best_score_)\n",
    "\n",
    "# 8) Evaluate best estimators on test set\n",
    "best_rf = grid_rf.best_estimator_\n",
    "best_svm = grid_svm.best_estimator_\n",
    "\n",
    "for name, estimator in [('RandomForest', best_rf), ('SVM', best_svm)]:\n",
    "    y_pred = estimator.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print(f\"\\n{name} Test Accuracy: {acc:.3f}\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# 9) Quick check of Decision Tree importance (train a tree for interpretability)\n",
    "models['decision_tree'].fit(X_train, y_train)\n",
    "dt_clf = models['decision_tree'].named_steps['clf']\n",
    "print(\"\\nDecision Tree feature importances (after preprocessing):\")\n",
    "print(dt_clf.feature_importances_)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
